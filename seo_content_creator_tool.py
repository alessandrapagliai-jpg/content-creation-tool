# -*- coding: utf-8 -*-
"""SEO-Content-Creator-Tool.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xpPG8YxkNrl4dTsXJvwhqmjUCP2LF_vX
"""

import streamlit as st
import requests
from serpapi import GoogleSearch
from bs4 import BeautifulSoup
from openai import OpenAI
from docx import Document
from io import BytesIO


# ===== CONFIG =====
st.set_page_config(page_title="SEO AI Writer Pro", layout="wide")

# ===== SIDEBAR =====
st.sidebar.title("‚öôÔ∏è Impostazioni")

SERPAPI_KEY = st.sidebar.text_input("üîë SerpAPI Key", type="password")
OPENAI_KEY = st.sidebar.text_input("üîë OpenAI API Key", type="password")


def get_openai_client():
    return OpenAI(api_key=OPENAI_KEY)


# ===== FUNZIONI =====

def extract_metadata(html):
    """Estrae Title, H1, Meta Description da una pagina HTML."""
    soup = BeautifulSoup(html, "html.parser")

    # Title
    title = soup.title.string.strip() if soup.title else ""

    # H1
    h1_tag = soup.find("h1")
    h1 = h1_tag.get_text(strip=True) if h1_tag else ""

    # Meta Description
    meta = soup.find("meta", attrs={"name": "description"})
    meta_desc = meta["content"].strip() if meta and "content" in meta.attrs else ""

    return title, h1, meta_desc


def fetch_page(url):
    """Scarica HTML e testo pulito."""
    try:
        resp = requests.get(url, timeout=10)
        html = resp.text
        soup = BeautifulSoup(html, "html.parser")

        # pulizia
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()

        text = " ".join(soup.get_text().split())
        return html, text[:10000]
    except:
        return "", ""


def get_top3_competitors(keyword):
    """Recupera i primi 3 risultati organici della SERP IT."""
    params = {
        "engine": "google",
        "q": keyword,
        "hl": "it",
        "gl": "it",
        "num": 3,
        "api_key": SERPAPI_KEY
    }

    search = GoogleSearch(params)
    results = search.get_dict()
    organic = results.get("organic_results", [])

    return [
        {"title": r.get("title"), "link": r.get("link")}
        for r in organic[:3]
    ]


def generate_content(keyword, competitors):
    """Genera un articolo unico fondendo info competitor."""
    merged = ""

    for i, comp in enumerate(competitors, start=1):
        merged += f"""
### COMPETITOR {i}
URL: {comp['link']}

TITLE: {comp['html_title']}
H1: {comp['h1']}
META: {comp['meta_desc']}

CONTENUTO:
{comp['text']}

-------------------------------------------------------
"""

    prompt = f"""
Sei un SEO content writer esperto in skincare.

Crea un articolo completo e originale sulla keyword:
**{keyword}**

Ispirandoti ai competitor senza copiare, genera un contenuto:

- SEO friendly
- con H2/H3
- molto approfondito
- tono professionale ma accessibile
- basato sulle informazioni fornite

Dati competitor:
{merged}

Scrivi l‚Äôarticolo ora.
"""

    client = get_openai_client()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content


def export_word(text, filename="articolo.docx"):
    """Crea file Word e ritorna BytesIO."""
    doc = Document()
    for line in text.split("\n"):
        if line.strip():
            doc.add_paragraph(line)
        else:
            doc.add_paragraph("")

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


# ===== UI STREAMLIT =====

st.title("üß† SEO AI Writer PRO")
st.write("Generatore SEO con estrazione competitor (Title, H1, Meta) + contenuto AI + export Word.")

keyword = st.text_input("üîç Keyword", placeholder="es. siero acido ialuronico")
start = st.button("üöÄ Genera articolo")

if start:
    if not SERPAPI_KEY or not OPENAI_KEY:
        st.error("‚ö†Ô∏è Inserisci SerpAPI Key e OpenAI Key!")
        st.stop()

    if not keyword.strip():
        st.error("‚ö†Ô∏è Inserisci una keyword valida!")
        st.stop()

    st.info("üîé Recupero top 3 competitor...")
    competitors = get_top3_competitors(keyword)

    if not competitors:
        st.error("‚ùå Nessun risultato trovato.")
        st.stop()

    enriched = []
    st.info("üì• Scarico contenuti competitor...")

    for comp in competitors:
        html, text = fetch_page(comp["link"])
        html_title, h1, meta_desc = extract_metadata(html)

        enriched.append({
            **comp,
            "html_title": html_title,
            "h1": h1,
            "meta_desc": meta_desc,
            "text": text
        })

    st.info("üß¨ Generazione articolo con GPT...")
    article = generate_content(keyword, enriched)

    st.success("‚ú® Articolo generato!")

    st.markdown(article)

    # EXPORT WORD
    buffer = export_word(article, f"articolo_{keyword}.docx")

    st.download_button(
        label="üìÑ Scarica Word (.docx)",
        data=buffer,
        file_name=f"articolo_{keyword.replace(' ', '_')}.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )